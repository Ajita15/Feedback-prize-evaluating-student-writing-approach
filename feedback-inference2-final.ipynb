{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4a02fc",
   "metadata": {
    "papermill": {
     "duration": 0.026368,
     "end_time": "2022-03-14T05:45:34.002302",
     "exception": false,
     "start_time": "2022-03-14T05:45:33.975934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Approach 2\n",
    "   - For Feedback prize-2021 competition, approach 2 will be divide each content into batch of 512, in that way we won't need to trim the content till 512 .\n",
    "   - https://towardsdatascience.com/how-to-apply-transformers-to-any-length-of-text-a5601410af7f - Followed this blog fir this approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5de4ac",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-14T05:45:34.084117Z",
     "iopub.status.busy": "2022-03-14T05:45:34.079814Z",
     "iopub.status.idle": "2022-03-14T05:45:34.096061Z",
     "shell.execute_reply": "2022-03-14T05:45:34.097031Z",
     "shell.execute_reply.started": "2022-03-14T05:44:10.998464Z"
    },
    "papermill": {
     "duration": 0.066771,
     "end_time": "2022-03-14T05:45:34.097313",
     "exception": false,
     "start_time": "2022-03-14T05:45:34.030542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65320782",
   "metadata": {
    "papermill": {
     "duration": 0.0164,
     "end_time": "2022-03-14T05:45:34.131418",
     "exception": false,
     "start_time": "2022-03-14T05:45:34.115018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Load the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8b7b0fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T05:45:34.170800Z",
     "iopub.status.busy": "2022-03-14T05:45:34.170138Z",
     "iopub.status.idle": "2022-03-14T05:45:37.018148Z",
     "shell.execute_reply": "2022-03-14T05:45:37.017657Z",
     "shell.execute_reply.started": "2022-03-14T05:43:05.046636Z"
    },
    "papermill": {
     "duration": 2.870374,
     "end_time": "2022-03-14T05:45:37.018310",
     "exception": false,
     "start_time": "2022-03-14T05:45:34.147936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c5fdd52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T05:45:37.097842Z",
     "iopub.status.busy": "2022-03-14T05:45:37.097223Z",
     "iopub.status.idle": "2022-03-14T05:45:37.103113Z",
     "shell.execute_reply": "2022-03-14T05:45:37.102462Z",
     "shell.execute_reply.started": "2022-03-14T05:43:07.874230Z"
    },
    "papermill": {
     "duration": 0.06981,
     "end_time": "2022-03-14T05:45:37.103283",
     "exception": false,
     "start_time": "2022-03-14T05:45:37.033473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c8ece60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T05:45:37.147472Z",
     "iopub.status.busy": "2022-03-14T05:45:37.146762Z",
     "iopub.status.idle": "2022-03-14T05:45:37.150465Z",
     "shell.execute_reply": "2022-03-14T05:45:37.150970Z",
     "shell.execute_reply.started": "2022-03-14T05:43:09.526812Z"
    },
    "papermill": {
     "duration": 0.031092,
     "end_time": "2022-03-14T05:45:37.151122",
     "exception": false,
     "start_time": "2022-03-14T05:45:37.120030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'B-Claim',\n",
       " 1: 'I-Claim',\n",
       " 2: 'B-Evidence',\n",
       " 3: 'I-Evidence',\n",
       " 4: 'B-Position',\n",
       " 5: 'I-Position',\n",
       " 6: 'B-Concluding Statement',\n",
       " 7: 'I-Concluding Statement',\n",
       " 8: 'B-Lead',\n",
       " 9: 'I-Lead',\n",
       " 10: 'B-Counterclaim',\n",
       " 11: 'I-Counterclaim',\n",
       " 12: 'B-Rebuttal',\n",
       " 13: 'I-Rebuttal',\n",
       " 14: 'O'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pprint as pprint\n",
    "label_to_idx = {'B-Claim': 0, 'I-Claim': 1,\n",
    "                'B-Evidence': 2, 'I-Evidence': 3,\n",
    "                'B-Position': 4, 'I-Position': 5,\n",
    "                'B-Concluding Statement': 6, 'I-Concluding Statement': 7,\n",
    "                'B-Lead': 8, 'I-Lead': 9,\n",
    "                'B-Counterclaim': 10, 'I-Counterclaim': 11,\n",
    "                'B-Rebuttal': 12, 'I-Rebuttal': 13,\n",
    "                'O': 14}\n",
    "idx_to_label = {v:k for k,v in label_to_idx.items()}\n",
    "idx_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cf4ef8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T05:45:37.190314Z",
     "iopub.status.busy": "2022-03-14T05:45:37.189506Z",
     "iopub.status.idle": "2022-03-14T05:45:37.252960Z",
     "shell.execute_reply": "2022-03-14T05:45:37.252445Z",
     "shell.execute_reply.started": "2022-03-14T05:44:22.959857Z"
    },
    "papermill": {
     "duration": 0.085051,
     "end_time": "2022-03-14T05:45:37.253090",
     "exception": false,
     "start_time": "2022-03-14T05:45:37.168039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "tokenizer = BertTokenizerFast.from_pretrained('../input/feedback-nb4/bert-base-uncased-tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decf8310",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T05:45:37.288200Z",
     "iopub.status.busy": "2022-03-14T05:45:37.287350Z",
     "iopub.status.idle": "2022-03-14T05:45:45.858097Z",
     "shell.execute_reply": "2022-03-14T05:45:45.858590Z",
     "shell.execute_reply.started": "2022-03-14T05:44:25.710524Z"
    },
    "papermill": {
     "duration": 8.589737,
     "end_time": "2022-03-14T05:45:45.858762",
     "exception": false,
     "start_time": "2022-03-14T05:45:37.269025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained('../input/feedback-nb4/feedback-bert-uncased-model2')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb96e0ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T05:45:45.928657Z",
     "iopub.status.busy": "2022-03-14T05:45:45.926910Z",
     "iopub.status.idle": "2022-03-14T05:45:45.929311Z",
     "shell.execute_reply": "2022-03-14T05:45:45.929717Z",
     "shell.execute_reply.started": "2022-03-14T05:44:34.107078Z"
    },
    "papermill": {
     "duration": 0.05315,
     "end_time": "2022-03-14T05:45:45.929857",
     "exception": false,
     "start_time": "2022-03-14T05:45:45.876707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_pred(content):\n",
    "    sentence = content.strip().split()\n",
    "    # Step1 - Call the tokenizer to encode\n",
    "    encoding = tokenizer.encode_plus(sentence,\n",
    "                                     add_special_tokens=False,\n",
    "                                     return_tensors=\"pt\",\n",
    "                                     is_split_into_words=True,\n",
    "                                     return_offsets_mapping=True)\n",
    "    \n",
    "    # Step2 - divide it into chunks\n",
    "    chunksize = 512\n",
    "    input_id_chunks = list(encoding['input_ids'][0].split(chunksize - 2))\n",
    "    mask_chunks = list(encoding['attention_mask'][0].split(chunksize - 2))\n",
    "    offset_mapping_chunks = list(encoding['offset_mapping'][0].split(chunksize - 2))\n",
    "    \n",
    "    # Step3: loop through each chunk\n",
    "    for i in range(len(input_id_chunks)):\n",
    "        # add CLS and SEP tokens to input IDs\n",
    "        input_id_chunks[i] = torch.cat([\n",
    "            torch.tensor([101]), input_id_chunks[i], torch.tensor([102])\n",
    "        ])\n",
    "        # add attention tokens to attention mask\n",
    "        mask_chunks[i] = torch.cat([\n",
    "            torch.tensor([1]), mask_chunks[i], torch.tensor([1])\n",
    "        ])\n",
    "\n",
    "        # add offset_mapping tokens to offset_maps\n",
    "        offset_mapping_chunks[i] = torch.cat([\n",
    "            torch.tensor([[0,0]]), offset_mapping_chunks[i], torch.tensor([[0,0]])\n",
    "        ])\n",
    "        \n",
    "    # Step4: get required padding length\n",
    "    pad_len = chunksize - input_id_chunks[i].shape[0]\n",
    "    # check if tensor length satisfies required chunk size\n",
    "    if pad_len > 0:\n",
    "        # if padding length is more than 0, we must add padding\n",
    "        input_id_chunks[i] = torch.cat([\n",
    "            input_id_chunks[i], torch.Tensor([0] * pad_len)\n",
    "        ])\n",
    "        mask_chunks[i] = torch.cat([\n",
    "            mask_chunks[i], torch.Tensor([0] * pad_len)\n",
    "        ])\n",
    "        offset_mapping_chunks[i] = torch.cat([\n",
    "            offset_mapping_chunks[i], torch.Tensor([[0,0]] * pad_len)\n",
    "        ])\n",
    "        \n",
    "    # Step 5: Stack the chunks\n",
    "    input_ids = torch.stack(input_id_chunks)\n",
    "    attention_mask = torch.stack(mask_chunks)\n",
    "    offset_mapping_merged = torch.stack(offset_mapping_chunks)\n",
    "\n",
    "    input_ids = input_ids.long()\n",
    "    attention_mask = attention_mask.int()\n",
    "    \n",
    "    # Step6 : unsqueeze it\n",
    "    input_ids = input_ids.unsqueeze(0)\n",
    "    attention_mask = attention_mask.unsqueeze(0)\n",
    "    offset_mapping_merged = offset_mapping_merged.unsqueeze(0)\n",
    "\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    offset_mapping_merged = offset_mapping_merged.to(device)\n",
    "    \n",
    "    # Step7: Call the model\n",
    "    outputs = model(input_ids[0], attention_mask=attention_mask[0])\n",
    "    tr_logits = outputs[0]\n",
    "    tr_logits_mod = torch.argmax(tr_logits, axis=2)\n",
    "    \n",
    "    \n",
    "    # Step8 - map sub_words to words\n",
    "    MAX_LEN = 512\n",
    "    tokens_words = [[-1] * MAX_LEN for i in range(tr_logits_mod.shape[0])]\n",
    "    \n",
    "    w_i = 0\n",
    "    off = offset_mapping_merged[0]\n",
    "    for itr1 in range(off.shape[0]):\n",
    "        for itr, off_map in enumerate(off[itr1]):\n",
    "            if off_map[0] == 0 and off_map[1] != 0:\n",
    "                w_i += 1\n",
    "                tokens_words[itr1][itr] = w_i\n",
    "            elif off_map[0] != 0 and off_map[1] != 0:\n",
    "                tokens_words[itr1][itr] = w_i\n",
    "                \n",
    "        \n",
    "    return tr_logits_mod, tokens_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a03c899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T05:45:45.975134Z",
     "iopub.status.busy": "2022-03-14T05:45:45.974227Z",
     "iopub.status.idle": "2022-03-14T05:45:45.976055Z",
     "shell.execute_reply": "2022-03-14T05:45:45.976567Z",
     "shell.execute_reply.started": "2022-03-14T05:44:42.208693Z"
    },
    "papermill": {
     "duration": 0.02999,
     "end_time": "2022-03-14T05:45:45.976705",
     "exception": false,
     "start_time": "2022-03-14T05:45:45.946715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_predictions(tr_logits_mod, tokens_words):\n",
    "    \n",
    "    # Step1 - reshape the logits and tokens_words\n",
    "    tr_logits_merged = torch.reshape(tr_logits_mod, (1, -1))\n",
    "    tokens_words_merged = []\n",
    "    for tokens in tokens_words:\n",
    "        tokens_words_merged.extend(tokens)\n",
    "        \n",
    "    MAX_LEN_MOD = len(tokens_words_merged)\n",
    "    all_predictions = {}\n",
    "    pred = tr_logits_merged[0]\n",
    "    i = 0\n",
    "    while i<MAX_LEN_MOD:\n",
    "        prediction = []\n",
    "        start = pred[i]\n",
    "        if start in [0,2,4,6,8,10,12,14]:\n",
    "            label = idx_to_label[start.item()]\n",
    "            label_mod = label.replace(\"B-\", \"\")\n",
    "            prediction.append(tokens_words_merged[i])\n",
    "            i += 1\n",
    "            if i>=MAX_LEN_MOD: break\n",
    "            while pred[i]==start+1:\n",
    "                # if we have \"I-\" after \"B-\" \n",
    "                if not tokens_words_merged[i] in prediction:\n",
    "                    prediction.append(tokens_words_merged[i])\n",
    "                i += 1\n",
    "                if i>=MAX_LEN_MOD: break\n",
    "        else:\n",
    "            i += 1\n",
    "        prediction = [x for x in prediction if x!=-1]\n",
    "        if len(prediction)>4:\n",
    "            if label_mod not in all_predictions:\n",
    "                all_predictions[label_mod] = [' '.join([str(x) for x in prediction])]\n",
    "            else:\n",
    "                all_predictions[label_mod].append(' '.join([str(x) for x in prediction]))\n",
    "                \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7df00bbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T05:45:46.016175Z",
     "iopub.status.busy": "2022-03-14T05:45:46.015402Z",
     "iopub.status.idle": "2022-03-14T05:45:48.142034Z",
     "shell.execute_reply": "2022-03-14T05:45:48.141428Z",
     "shell.execute_reply.started": "2022-03-14T05:44:49.071319Z"
    },
    "papermill": {
     "duration": 2.149135,
     "end_time": "2022-03-14T05:45:48.142191",
     "exception": false,
     "start_time": "2022-03-14T05:45:45.993056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (754 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "row_df = [] # list will have the rows for submission_df\n",
    "folder = \"../input/feedback-prize-2021/test\"\n",
    "for file_name in os.listdir(folder):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        with open(os.path.join(folder, file_name), \"r\") as fin:\n",
    "            content = fin.read()\n",
    "            \n",
    "    # get the predictions from the model\n",
    "    tr_logits_mod, tokens_words = model_pred(content)\n",
    "    \n",
    "    # convert the predictions into the desired format\n",
    "    all_predictions = get_predictions(tr_logits_mod, tokens_words)\n",
    "    \n",
    "    # store the predicitons in the list\n",
    "    for label in all_predictions:\n",
    "        for pred_str in all_predictions[label]:\n",
    "            ind_dct = {}\n",
    "            ind_dct['id'] = file_name.replace(\".txt\", \"\")\n",
    "            ind_dct['class'] = label\n",
    "            ind_dct['predictionstring'] = pred_str\n",
    "            row_df.append(ind_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d0c04f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T05:45:48.191589Z",
     "iopub.status.busy": "2022-03-14T05:45:48.190646Z",
     "iopub.status.idle": "2022-03-14T05:45:48.201746Z",
     "shell.execute_reply": "2022-03-14T05:45:48.202262Z",
     "shell.execute_reply.started": "2022-03-14T05:44:58.068781Z"
    },
    "papermill": {
     "duration": 0.039963,
     "end_time": "2022-03-14T05:45:48.202427",
     "exception": false,
     "start_time": "2022-03-14T05:45:48.162464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Lead</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Position</td>\n",
       "      <td>42 43 44 45 46 47 48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Claim</td>\n",
       "      <td>50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Claim</td>\n",
       "      <td>67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Claim</td>\n",
       "      <td>197 198 199 200 201 202 203 204 205 206 207 20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id     class                                   predictionstring\n",
       "0  0FB0700DAF44      Lead  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...\n",
       "1  0FB0700DAF44  Position                               42 43 44 45 46 47 48\n",
       "2  0FB0700DAF44     Claim    50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65\n",
       "3  0FB0700DAF44     Claim  67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 8...\n",
       "4  0FB0700DAF44     Claim  197 198 199 200 201 202 203 204 205 206 207 20..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.DataFrame(row_df)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43e4fb74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T05:45:48.243426Z",
     "iopub.status.busy": "2022-03-14T05:45:48.242827Z",
     "iopub.status.idle": "2022-03-14T05:45:48.246787Z",
     "shell.execute_reply": "2022-03-14T05:45:48.246294Z",
     "shell.execute_reply.started": "2022-03-10T17:46:18.795573Z"
    },
    "papermill": {
     "duration": 0.025903,
     "end_time": "2022-03-14T05:45:48.246915",
     "exception": false,
     "start_time": "2022-03-14T05:45:48.221012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sub_df[sub_df['id'] == 'DF920E0A7337']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9df5ca91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T05:45:48.287479Z",
     "iopub.status.busy": "2022-03-14T05:45:48.286685Z",
     "iopub.status.idle": "2022-03-14T05:45:48.292802Z",
     "shell.execute_reply": "2022-03-14T05:45:48.292374Z",
     "shell.execute_reply.started": "2022-03-14T05:45:00.731043Z"
    },
    "papermill": {
     "duration": 0.028173,
     "end_time": "2022-03-14T05:45:48.292941",
     "exception": false,
     "start_time": "2022-03-14T05:45:48.264768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc03fca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T05:45:48.332386Z",
     "iopub.status.busy": "2022-03-14T05:45:48.331676Z",
     "iopub.status.idle": "2022-03-14T05:45:48.334577Z",
     "shell.execute_reply": "2022-03-14T05:45:48.335050Z",
     "shell.execute_reply.started": "2022-03-14T05:45:03.054218Z"
    },
    "papermill": {
     "duration": 0.024971,
     "end_time": "2022-03-14T05:45:48.335185",
     "exception": false,
     "start_time": "2022-03-14T05:45:48.310214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbee454",
   "metadata": {
    "papermill": {
     "duration": 0.01863,
     "end_time": "2022-03-14T05:45:48.371416",
     "exception": false,
     "start_time": "2022-03-14T05:45:48.352786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26.293136,
   "end_time": "2022-03-14T05:45:51.928407",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-14T05:45:25.635271",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
